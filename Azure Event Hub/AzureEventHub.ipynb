{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Event Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Azure Event Hub ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft Azure Event Hub is a cloud-based service that is used as a big data platform and event ingestion service by processing millions of events in seconds.  Data generated or stored in the source system can be sent to the event hub and the user can perform the necessary transformation on data and finally, it can be stored using real-time ingestion technique or by batch/storage processes. The azure event hub is used for anomaly detection, application logging, or applications where real-time data is needed like live dashboarding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Azure Event Hub work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure event hub processes data easily in real-time so that users can get more insight into data. It uses a distributed processing platform used in Hadoop to process data with low latency and has integration with data analytics services. Event hubs are like a “front door” to the event pipeline and act as an event ingester. Event ingester lies in between the event punisher and consumer. It is a unified streaming service to decouple the producer from the event consumer.\n",
    "\n",
    "\n",
    "- Event producers: It is an endpoint that engages customers with event hubs using the HTTP or Apache Kafka protocols. Any type of data sent to the hub is first published using the event publisher/producer.\n",
    "\n",
    "- Partitions: Event hub streams a message which is partitioned so that based on partition consumers can only read the particular subset of the partition of the streamed message.\n",
    "\n",
    "- Consumer groups: Event hub follows the mechanism of publishing and subscribing and this is enabled in the event hub using the consumer group. It provides the state, position, and offset view of the event hub. Based on the subscription of the consumer group they can view the event stream in the event hub. Consumer groups can read or view the stream based on their pace and offset.\n",
    "\n",
    "- Throughput units: To control the throughput capacity users can pre-purchase the units of capacity in the Azure Event Hub.\n",
    "\n",
    "- Event Receiver: it is an entity used to read the data from the event hub. AMQP 1.0 sessions are used to connect the All event hub consumers.  This session is used to deliver Event hub services as soon as they are available. For real-time streaming and ingestion of data, Apache Kafka uses Kafka consumers which are connected using Kafka protocol 1.0 or later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> Install the Azure EventHub package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-eventhub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> To receive events using Azure Blob Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-eventhub-checkpointstoreblob-aio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Asynchronously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### >> To Send Events to Azure Event Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import asyncio\n",
    "from azure.eventhub.aio import EventHubProducerClient\n",
    "from azure.eventhub import EventData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection Strings and Names\n",
    "EH_conn_string = \"Endpoint=sb://eh-testns.servicebus.windows.net/;SharedAccessKeyName=EHTestPolicyName;SharedAccessKey=Bw2rPoQ64RDxUOqe9W0ekM3l+WGSehG84vbr8TW8AEo=;EntityPath=ehtestname\"\n",
    "EH_Name = \"ehtestname\"\n",
    "async def run():\n",
    "    # Create a producer client to send messages to the event hub\n",
    "    producer = EventHubProducerClient.from_connection_string(conn_str=EH_conn_string_, eventhub_name=EH_Name)\n",
    "    async with producer:\n",
    "        # Create a batch.\n",
    "        event_data_batch = await producer.create_batch()\n",
    "\n",
    "        # Add events to the batch.\n",
    "        event_data_batch.add(EventData('This is First event '))\n",
    "        event_data_batch.add(EventData('This is Second event'))\n",
    "        event_data_batch.add(EventData('This is Third event'))\n",
    "\n",
    "        # Send the batch of events to the event hub.\n",
    "        await producer.send_batch(event_data_batch)\n",
    "        \n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(run())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >> To Receive Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import asyncio\n",
    "from azure.eventhub.aio import EventHubConsumerClient\n",
    "from azure.eventhub.extensions.checkpointstoreblobaio import BlobCheckpointStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EH_conn_string = \"Endpoint=sb://eh-testns.servicebus.windows.net/;SharedAccessKeyName=EHTestPolicyName;SharedAccessKey=Bw2rPoQ64RDxUOqe9W0ekM3l+WGSehG84vbr8TW8AEo=;EntityPath=ehtestname\"\n",
    "EH_Name = \"ehtestname\"\n",
    "BlobStorageConnString = \"DefaultEndpointsProtocol=https;AccountName=teststorageaccname;AccountKey=Lpf3kfsOriMMXDpaoQo/YHDrgLK/oABnoxW7/yKEltn5f6XrryXCFDZ0HDmMUnifVgg21BjTyfYA+AStURZrUQ==;EndpointSuffix=core.windows.net\"\n",
    "ContainerName = \"testcontainername\"\n",
    "\n",
    "async def on_event(partition_context, event):\n",
    "    # Print the event data.\n",
    "    print(\"Received the event: \\\"{}\\\" from the partition with ID: \\\"{}\\\"\".format(event.body_as_str(encoding='UTF-8'), partition_context.partition_id))\n",
    "\n",
    "    # Update the checkpoint so that the program doesn't read the events\n",
    "    # that it has already read when you run it next time.\n",
    "    await partition_context.update_checkpoint(event)\n",
    "\n",
    "async def main():\n",
    "    # Create an Azure blob checkpoint store to store the checkpoints.\n",
    "    checkpoint_store = BlobCheckpointStore.from_connection_string(BlobStorageConnString, ContainerName)\n",
    "\n",
    "    # Create a consumer client for the event hub.\n",
    "    client = EventHubConsumerClient.from_connection_string(EH_conn_string, consumer_group=\"$Default\", eventhub_name=EH_Name, checkpoint_store=checkpoint_store)\n",
    "    async with client:\n",
    "        # Call the receive method. Read from the beginning of the partition (starting_position: \"-1\")\n",
    "        await client.receive(on_event=on_event,  starting_position=\"-1\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    loop = asyncio.get_event_loop()\n",
    "    # Run the main method.\n",
    "    loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Synchrounously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from azure.eventhub import EventHubProducerClient\n",
    "from azure.eventhub import EventHubConsumerClient\n",
    "from azure.eventhub import EventHubProducerClient, EventHubSharedKeyCredential\n",
    "from azure.eventhub import EventHubProducerClient, EventHubSharedKeyCredential\n",
    "from azure.eventhub import EventData\n",
    "import os\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EH_Name_Space = \"EH-TestNS\"\n",
    "EH_Shared_Policy = \"RootManageSharedAccessKey\"\n",
    "EH_Shared_Access_Key = \"UzDpteVNxCzjFtFL2C/uvcGp6B4/1JHe9Oqno88JHj4=\"\n",
    "EH_conn_string = \"Endpoint=sb://eh-testns.servicebus.windows.net/;SharedAccessKeyName=EHTestPolicyName;SharedAccessKey=Bw2rPoQ64RDxUOqe9W0ekM3l+WGSehG84vbr8TW8AEo=;EntityPath=ehtestname\"\n",
    "EH_Name = \"ehtestname\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Create Event Producer Client (legacy method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = EventHubSharedKeyCredential(EH_Shared_Policy, EH_Shared_Access_Key)\n",
    "producer = EventHubProducerClient(\n",
    "fully_qualified_namespace=EH_Name_Space,\n",
    "eventhub_name=EH_Name,\n",
    "credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Create Event Producer Client (from_connection_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Producer Client\n",
    "\n",
    "# event_hub_connection_string  = os.environ['Endpoint=sb://eh-testns.servicebus.windows.net/;SharedAccessKeyName=EHTestPolicyName;SharedAccessKey=Bw2rPoQ64RDxUOqe9W0ekM3l+WGSehG84vbr8TW8AEo=;EntityPath=ehtestname']\n",
    "# event_hub_name = os.environ['ehtestname']\n",
    "\n",
    "producer = EventHubProducerClient.from_connection_string(\n",
    "conn_str=EH_conn_string,\n",
    "eventhub_name=EH_Name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Create Event Consumer Client (Legacy Method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = EventHubSharedKeyCredential(EH_Shared_Policy, EH_Shared_Access_Key)\n",
    "consumer = EventHubConsumerClient(\n",
    "fully_qualified_namespace=EH_Name_Space,\n",
    "eventhub_name=EH_Name,\n",
    "credential=credential,\n",
    "consumer_group='$Default'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Create Event Consumer Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Consumer Client\n",
    "consumer = EventHubConsumerClient.from_connection_string(\n",
    "conn_str=EH_conn_string,\n",
    "eventhub_name=EH_Name,\n",
    "consumer_group='$Default',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Create Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send and Receive Events\n",
    "\n",
    "# Event Data\n",
    "event_data1 = EventData(\"String Data\")\n",
    "event_data2 = EventData(b\"Bytes Data\")\n",
    "\n",
    "# Create Event Batch\n",
    "event_data_batch = producer.create_batch()\n",
    "\n",
    "# Add Events to Batch\n",
    "event_data_batch.add(event_data1)\n",
    "event_data_batch.add(event_data2)\n",
    "\n",
    "# Send Single Event\n",
    "# producer.send_event(event_data1)\n",
    "\n",
    "# Send Event Batch\n",
    "producer.send_batch(event_data_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >> Receive Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receive Events\n",
    "\n",
    "def on_event(partition_context, event):\n",
    "    print(partition_context.partition_id)\n",
    "    \n",
    "consumer.receive(on_event=on_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
